<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.242">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2021-03-10">
<meta name="description" content="Summary of Day 3 at FAccT 2021. Julian Anguin’s Markup, language models, measurements, and data average">

<title>Hongsup Shin - FAccT 2021. Journalism, data leverage, education, and language models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Hongsup Shin</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../publications.html">
 <span class="menu-text">Publications</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/hongsupshin"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/hongsupshin/"><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">FAccT 2021. Journalism, data leverage, education, and language models</h1>
                  <div>
        <div class="description">
          Summary of Day 3 at FAccT 2021. Julian Anguin’s Markup, language models, measurements, and data average
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">conference</div>
                <div class="quarto-category">journalism</div>
                <div class="quarto-category">measurement</div>
                <div class="quarto-category">education</div>
                <div class="quarto-category">language models</div>
                <div class="quarto-category">responsible AI</div>
                <div class="quarto-category">ML</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 10, 2021</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="keynote-algorithms-accountability-and-journalism" class="level2">
<h2 class="anchored" data-anchor-id="keynote-algorithms-accountability-and-journalism">Keynote: Algorithms, Accountability, and Journalism</h2>
<p>The final keynote was given by Julia Anguin, an investigative journalist and a co-founder of <a href="https://themarkup.org/">The Markup</a>, “a nonprofit newsroom that investigates how powerful institutions are using technology to change our society.” I was already familiar with her body of her because she’s famous for <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">her ProPublica article</a> on racial bias in the risk assessment software, COMPAS. Her talk consisted of two parts. First, she talked about how her organization Markup is run and what methods they use to publish investigative journalism reports. Later, she gave several examples of their work from last year, which was mostly on algorithm auditing.</p>
<p>Markup consists of <strong>engineers and journalists</strong>. It’s interesting to hear her saying that engineers are essentially investigative journalists themselves. They collaborate with journalists in the team but they bring tech expertise to tech reporting. Once Markup has written a report, they have an extensive vetting process (called the “bulletproof” stage) where they actively seek out critiques from various external experts. What’s interesting is that each work product comes with a pair of publications; a news article targeting general public and <strong>an extensively detailed methodological write-up</strong>. They also have established a practice of publishing datasets and codes so that other people can replicate their analysis and apply those to their own projects.</p>
<p>When she gave examples of their algorithm auditing projects, it was amusing to learn about various novel approaches they have made to probe algorithms. In one project, they simply analyzed search results, but in other projects, they created numerous web accounts to try to reverse-engineer opaque decisions algorithms make. Markup also seemed to put resources into creating tools such as <a href="https://themarkup.org/blacklight">Blacklight</a> that runs privacy tests on virtual browsers for websites to inspect their privacy violations, or <a href="https://themarkup.org/series/citizen-browser">Citizen Browser</a> where volunteer citizens use Markup’s app to scrape data from Facebook so that the team can examine various decisions the Facebook app makes.</p>
<p>During the Q&amp;A, one memorable remark she made was <strong>all data is political.</strong> Whether it’s leaked, accessed through protocols, or publicly available, data collection starts with a certain intention. She said there’s no national database on police violence in the US, which reveals the political will and intention of the US government, which was revealing. To fight this issue, she said it’s really <strong>important to know the limitations of data and be very transparent about it.</strong></p>
<p>She mentioned that Markup often tries to co-publish pieces with other news companies for distribution reasons. She said sometimes the process is challenging because these organizations do not have technical experts to review their lengthy methodological write-up. This resonated with me most because this is what I’ve been experiencing while volunteering at a local non-profit. Nevertheless, when one of the audience members asked her about how individual tech workers help, she said the most straightforward way to help journalists it via financially supporting them, especially the local news organizations.</p>
</section>
<section id="data-leverage" class="level2">
<h2 class="anchored" data-anchor-id="data-leverage">Data Leverage</h2>
<p>In the tech world, there’s a tendency to trivialize data labor. Tech companies also conduct problematic practices to collect data. For the public, who are in a very vulnerable position, what can they do? <a href="https://dl.acm.org/doi/pdf/10.1145/3442188.3445885"><em>Data Leverage: A Framework for Empowering the Public in its Relationship with Technology Companies</em></a> explores several ways to leverage the fact that we the public are data providers. The defined the data leverage as <strong>power to influence a company held by those who implicitly or explicitly contribute data on which companies rely</strong>. The large goal of identifying data leverage is to give more agency to people. They explore three options; data strike, data poisoning, and conscious data contribution. Each options has its pros and cons and some have more complex legal landscape to navigate. Personally I found <strong>data poisoning</strong> most interesting, which is about inputting fake and random data (somewhat similar to adversarial attacks).</p>
</section>
<section id="measurement" class="level2">
<h2 class="anchored" data-anchor-id="measurement">Measurement</h2>
<p>Any attempts to address FAccT topics in mathematical models begin with constructing a measurement; we are trying to measure unobservable and abstract concepts. <a href="https://dl.acm.org/doi/pdf/10.1145/3442188.3445901"><em>Measurement and Fairness</em></a> proposes <strong>measurement modeling framework</strong> in fairness research in computer science. The authors target fairness specifically because fairness itself is an <strong>essentially contested construct</strong>; it’s heavily context-dependent and some constructs are conflicting. Besides, in general, determining which measurements and metrics to use requires extreme caution. To mitigate these problems, the authors came up with two criteria; <strong>construct reliability</strong> and <strong>construct validity</strong>. The former checks whether similar inputs can return similar measurements. The latter checks whether measurements are meaningful and useful such as whether they capture relevant events, or whether the impact from using the measurements has been addressed.</p>
</section>
<section id="education" class="level2">
<h2 class="anchored" data-anchor-id="education">Education</h2>
<p>Since last year, the conference has been including more papers about ethics education. This year, <a href="https://dl.acm.org/doi/pdf/10.1145/3442188.3445914"><em>“You Can’t Sit With Us”: Exclusionary Pedagogy in AI Ethics Education</em></a> stood out. This survey paper collected more than 250 AI ethics courses in computer science curriculums from more than 100 universities around the world and analyzed the pattern. Sadly, they found a predominant pattern of exclusion in many courses. The authors found this exclusion had many shapes; the discipline not valuing other ways of knowing, lack of collaboration with other disciplines, and lack of interest in learning other’s work. The fact that computer science itself can’t solve AI ethics problems, this seemed very worrisome.</p>
</section>
<section id="language-models" class="level2">
<h2 class="anchored" data-anchor-id="language-models">Language Models</h2>
<p>What happens when an authoritarian government and AI meet? <a href="https://dl.acm.org/doi/pdf/10.1145/3442188.3445916"><em>Censorship of Online Encyclopedias: Implications for NLP Models</em></a> explores how censorship in training data influence downstream processes in NLP applications using Chinese language models. One of the dataset they looked into was <a href="https://en.wikipedia.org/wiki/Baidu_Baike">Baidu Baike</a>, a censored language dataset that is often used in Chinese language models. They first checked the word embeddings and examined the position of words such as <em>democracy, surveillance, social control, CCP (Chinese Communist Party)</em> with respect to positive and negative words. They found that <em>democracy</em> often appeared with negative words and the rest in the example were the opposite. They also found similar pattern in a sentiment classification application that uses web news headlines. These results were concerning because as the authors addressed, these applications can be used to monitor public opinion and curate social media posts, essentially as a highly effective propaganda machine in a massive scale.</p>
<p>For those who’ve been following the news of Timit Gebru, an AI ethics researcher who was fired by Google, <a href="https://dl.acm.org/doi/pdf/10.1145/3442188.3445922"><em>On the Dangers of Stochastic Parrots:Can Language Models Be Too Big?</em></a> was the paper that was at the core. The paper explores potential risks of the current trend in language modeling where researchers and practitioner pay more attention to larger models. As shown in the paper, these models have <strong>billions, sometimes trillions of parameters</strong>. The first risk the authors bring up is environmental and financial cost. Studies have shown that <strong>training a single BERT base model (without tuning) requires as much energy as a trans-American flight</strong>. This gets more problematic if you become aware that <strong>most language models serve English-speaking communities</strong> and the most impacted communities from climate change are not those. There are more sinister risks too such as training data still lacking diversity (i.e., <strong>“big” doesn’t mean “diverse.”</strong>) and lacking oversight, which creates harmful effects. Plus, since many efforts and resources in ML community go into building large language models, other research topics are naturally overlooked. The authors suggest simple mitigation strategies - <strong>step back and think</strong>; evaluate various approaches, ask yourself if we really need large models, and conduct <strong>pre-mortem</strong> analysis.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>