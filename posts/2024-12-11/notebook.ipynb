{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning to follow instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to instruction fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "205-215"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gneral process\n",
    "1. Download dataset and format it\n",
    "2. Batch the dataset\n",
    "3. Create data loaders\n",
    "4. Load a pretrained LLM\n",
    "5. Instruction fine-tune the LLM\n",
    "6. Inspect the loss\n",
    "7. Extract responses\n",
    "8. Evaluate (qualitative)\n",
    "9. Score the response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing a dataset for supervised instruction fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1,100 instruction–response pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alpaca style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request. \"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion : train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing data into training batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pythorch `dataloader` can automatically create training batches\n",
    "- it uses default `collate` function to combine lists of samples into batches\n",
    "- but batching process for instruction fine-tuning is a bit more involved and requires us to create our own custom collate function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batching process in 5 steps:\n",
    "1. Format data using prompt template: instruction-response template\n",
    "2. Tokenize formatted data: encode to token IDs\n",
    "3. Adjust to the same length w/ padding tokens: end-of-text tokens (50256)\n",
    "4. Create target token IDs for training: input shifted by 1 + additional padding\n",
    "5. Replace padding tokens w/ placeholders: use -100 to exclude them from training loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implement an instruction dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(tokenizer.encode(full_text))\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "custom collate function\n",
    "- pads the training examples in each batch to the same length\n",
    "- only extend the sequence to match the longest on in the batch, not the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item) for item in batch)\n",
    "    inputs_lst = []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # new_item += [pad_token_id]\n",
    "        \n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded)\n",
    "        inputs_lst.append(inputs)\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (inputs_1, inputs_2, inputs_3)\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating input-target pairs: we shift the token IDs by one position to the right, and add the padding token ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item) for item in batch)\n",
    "    inputs_lst, target_lst = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item) + 1)\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        inputs_lst.append(inputs)\n",
    "        target_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    target_tensor = torch.stack(target_lst).to(device)\n",
    "    return inputs_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assign -100 placeholder to all padding tokens: exclude padding tokens from contributing to the training loss calculation\n",
    "- We retain one EOT token 50256 (not all EOT is converted to -100)\n",
    "- `allowed_max_length`: optionally limit the sample length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch, pad_token_id=50256, ignore_index=-100, device=\"cpu\", allowed_max_length=None\n",
    "):\n",
    "    batch_max_length = max(len(item) + 1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The impact of placeholder -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor([[-1.0, 1.0], [-0.5, 1.5]])\n",
    "targets_1 = torch.tensor([0, 1])  # Correct token indices to generate\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)\n",
    "\n",
    "logits_2 = torch.tensor([[-1.0, 1.0], [-0.5, 1.5], [-0.5, 1.5]])\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.nn.functional.cross_entropy()` docstring:\n",
    ">ignore_index (int, optional): Specifies a target value that is ignored\n",
    ">and does not contribute to the input gradient. When size_average is True, the loss is averaged over non-ignored targets. Note that\n",
    ">\n",
    ">ignore_index is only applicable when the target contains class indices.\n",
    ">\n",
    ">**Default: -100**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask out the target token IDs of the instruction -> loss is only computed for the generated response target IDs (but there are some opposing opinions too)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data loaders for an instruction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `partial` to prefill `device` and `allowed_max_length`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader can create batches of different lenghths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 92]) torch.Size([8, 92])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 90]) torch.Size([8, 90])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 92]) torch.Size([8, 92])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 92]) torch.Size([8, 92])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a pretrained LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 124-million-parameter model is too limited in capacity\n",
    "- we load the medium-sized model with 355 million parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": True,\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import text_to_token_ids, token_ids_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(\n",
    "    model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None\n",
    "):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits\n",
    "            )\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if (\n",
    "            idx_next == eos_id\n",
    "        ):  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Response:\n",
      "\n",
      "Write a response that appropriately completes the request. \n",
      "\n",
      "### Response:\n",
      "\n",
      "Write a response that appropriately completes the request. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The generate function returns the combined input and output: this was convenient previously since pretrained LLMs are primarily designed as text-completion models (=input and output are concatenated to create coherent and legible text)\n",
    "- But for model evaluation, we just want to focus on the generated response -> need to isolate the response (=subtract the length of the input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "\n",
      "Write a response that appropriately completes the request. \n",
      "\n",
      "### Response:\n",
      "\n",
      "Write a response that appropriately completes the request.\n"
     ]
    }
   ],
   "source": [
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning the LLM on instruction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import generate_text_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "\n",
    "def train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    eval_freq,\n",
    "    eval_iter,\n",
    "    start_context,\n",
    "    tokenizer,\n",
    "):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()  # Calculate loss gradients\n",
    "            optimizer.step()  # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(\n",
    "                    f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded, max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initial loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.285582447052002\n",
      "Validation loss: 4.1658350944519045\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.209, Val loss 3.150\n",
      "Ep 1 (Step 000005): Train loss 1.633, Val loss 1.520\n",
      "Ep 1 (Step 000010): Train loss 1.096, Val loss 1.163\n",
      "Ep 1 (Step 000015): Train loss 1.049, Val loss 1.071\n",
      "Ep 1 (Step 000020): Train loss 0.965, Val loss 1.027\n",
      "Ep 1 (Step 000025): Train loss 0.906, Val loss 0.992\n",
      "Ep 1 (Step 000030): Train loss 0.957, Val loss 0.968\n",
      "Ep 1 (Step 000035): Train loss 0.863, Val loss 0.941\n",
      "Ep 1 (Step 000040): Train loss 0.842, Val loss 0.934\n",
      "Ep 1 (Step 000045): Train loss 0.773, Val loss 0.918\n",
      "Ep 1 (Step 000050): Train loss 0.863, Val loss 0.906\n",
      "Ep 1 (Step 000055): Train loss 0.923, Val loss 0.887\n",
      "Ep 1 (Step 000060): Train loss 0.877, Val loss 0.875\n",
      "Ep 1 (Step 000065): Train loss 0.797, Val loss 0.858\n",
      "Ep 1 (Step 000070): Train loss 0.693, Val loss 0.852\n",
      "Ep 1 (Step 000075): Train loss 0.702, Val loss 0.845\n",
      "Ep 1 (Step 000080): Train loss 0.753, Val loss 0.836\n",
      "Ep 1 (Step 000085): Train loss 0.680, Val loss 0.826\n",
      "Ep 1 (Step 000090): Train loss 0.725, Val loss 0.816\n",
      "Ep 1 (Step 000095): Train loss 0.653, Val loss 0.814\n",
      "Ep 1 (Step 000100): Train loss 0.633, Val loss 0.799\n",
      "Ep 1 (Step 000105): Train loss 0.726, Val loss 0.793\n",
      "Ep 1 (Step 000110): Train loss 0.715, Val loss 0.787\n",
      "Ep 1 (Step 000115): Train loss 0.668, Val loss 0.784\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.   ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The\n",
      "Ep 2 (Step 000120): Train loss 0.594, Val loss 0.786\n",
      "Ep 2 (Step 000125): Train loss 0.625, Val loss 0.788\n",
      "Ep 2 (Step 000130): Train loss 0.581, Val loss 0.782\n",
      "Ep 2 (Step 000135): Train loss 0.547, Val loss 0.780\n",
      "Ep 2 (Step 000140): Train loss 0.577, Val loss 0.778\n",
      "Ep 2 (Step 000145): Train loss 0.520, Val loss 0.777\n",
      "Ep 2 (Step 000150): Train loss 0.522, Val loss 0.774\n",
      "Ep 2 (Step 000155): Train loss 0.598, Val loss 0.775\n",
      "Ep 2 (Step 000160): Train loss 0.584, Val loss 0.775\n",
      "Ep 2 (Step 000165): Train loss 0.535, Val loss 0.771\n",
      "Ep 2 (Step 000170): Train loss 0.439, Val loss 0.768\n",
      "Ep 2 (Step 000175): Train loss 0.481, Val loss 0.764\n",
      "Ep 2 (Step 000180): Train loss 0.538, Val loss 0.754\n",
      "Ep 2 (Step 000185): Train loss 0.565, Val loss 0.749\n",
      "Ep 2 (Step 000190): Train loss 0.442, Val loss 0.737\n",
      "Ep 2 (Step 000195): Train loss 0.468, Val loss 0.723\n",
      "Ep 2 (Step 000200): Train loss 0.408, Val loss 0.721\n",
      "Ep 2 (Step 000205): Train loss 0.474, Val loss 0.717\n",
      "Ep 2 (Step 000210): Train loss 0.518, Val loss 0.718\n",
      "Ep 2 (Step 000215): Train loss 0.536, Val loss 0.727\n",
      "Ep 2 (Step 000220): Train loss 0.413, Val loss 0.728\n",
      "Ep 2 (Step 000225): Train loss 0.487, Val loss 0.729\n",
      "Ep 2 (Step 000230): Train loss 0.423, Val loss 0.732\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.   ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.   ### Input: What is the chemical symbol for carbon? \n",
      "Training completed in 2.42 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=format_input(val_data[0]),\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time) / 60.0\n",
    "print(f\"Training completed in {execution_time:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(\n",
    "        MaxNLocator(integer=True)\n",
    "    )  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting and saving responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extract the model-generated response for each input in the test dataset, and collect them for manual analysis\n",
    "2. Evaluate the LLM to quantify the quality of the responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a horse.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> A type of cloud typically associated with thunderstorms is the active layer.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Robert Frost.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256,\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text) :].replace(\"### Response:\", \"\").strip()\n",
    "    )\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "236-249"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proper evaluation of instruction fine-tuning is challenging. Several approaches:\n",
    "- Short-answer + multiple-choice benchmarks (MMLU: Measuring Massive Multitask Language Understanding)\n",
    "- Human preference comparison to other LLMs (LMSYS chatbot arena)\n",
    "- Automated conversational benchmarks: AlpacaEval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here: AlpacaEval-inspired approach -> use another LLM to evaluate our model's response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating test set responses: we just add the model response to the existing test set dict so that we can easily compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:44<00:00,  2.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    "    \n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256,\n",
    "    )\n",
    "    \n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    \n",
    "    response_text = (\n",
    "        generated_text[len(input_text) :].replace(\"### Response:\", \"\").strip()\n",
    "    )\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "    \n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_output': 'The car is as fast as a horse.', 'model_response': 'The car is as fast as a horse.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: gpt2-small124M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\" # removes spaces, parentheses\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(\"Model saved to:\", file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the fine-tuned LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ollama for automatic evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative way: Use REST API to interact with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "def query_model(\n",
    "    prompt,\n",
    "    model=\"llama3.2\",\n",
    "    url=\"http://localhost:11434/api/chat\",\n",
    "):\n",
    "    # create data payload as a dictionary\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"options\": {\"seed\": 123, \"temprature\": 0.0, \"num_ctx\": 2048},\n",
    "    }\n",
    "    \n",
    "    # convert data payload to JSON and encode it to bytes (binary)\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "    request = urllib.request.Request(url, data=payload, method=\"POST\") # post method\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "    \n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line) # parse JSON into dictionary\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "    \n",
    "    return response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are herbivores, which means they primarily eat plant-based foods. Their diet typically consists of:\n",
      "\n",
      "1. Grasses: They love to graze on various types of grasses, including tall grasses, short grasses, and grass seeds.\n",
      "2. Hay: Llamas enjoy a variety of hay types, such as timothy hay, alfalfa hay, and clover hay.\n",
      "3. Grains: They may be fed grains like oats, corn, or barley in moderation.\n",
      "4. Fruits and vegetables: Fresh fruits and vegetables can be given to llamas as treats or added to their diet as a supplement.\n",
      "5. Forages: Llamas will also eat forages like leaves, branches, and shrubs.\n",
      "\n",
      "It's essential to note that llamas have specific nutritional needs, so it's crucial to provide them with a balanced diet that includes:\n",
      "\n",
      "* High-quality hay (70-80% of their diet)\n",
      "* Limited amounts of grains (10-20% of their diet)\n",
      "* Fresh fruits and vegetables (5-10% of their diet)\n",
      "\n",
      "A well-balanced diet will help maintain the llama's overall health, energy levels, and digestive system.\n"
     ]
    }
   ],
   "source": [
    "model = \"llama3.2\"\n",
    "result = query_model(\"What do Llamas eat?\", model=model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using llama to score the response quailty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a horse.\n",
      "\n",
      "Score:\n",
      ">> I would rate the model response \"The car is as fast as a horse\" a 20.\n",
      "\n",
      "This response does not use a simile (a comparison between two unlike things using \"like\" or \"as\") correctly. A simile should compare two unlike things, but in this case, comparing speed to a horse doesn't make sense.\n",
      "\n",
      "A correct simile would be something like \"The car is as fast as lightning.\" This response uses the word \"as\" to make a comparison between two unlike things (speed and lightning), which meets the criteria for a simile.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> A type of cloud typically associated with thunderstorms is the active layer.\n",
      "\n",
      "Score:\n",
      ">> I would rate the model response \"A type of cloud typically associated with thunderstorms is the active layer.\" as a 20.\n",
      "\n",
      "The reason for this low score is that the correct answer, \"cumulonimbus\", is a specific and well-known type of cloud that is commonly associated with thunderstorms. The model response, on the other hand, refers to an undefined term \"active layer\" which does not accurately describe any known type of cloud.\n",
      "\n",
      "A more accurate response would have provided the correct information about cumulonimbus clouds, such as their appearance, formation, and characteristics.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Robert Frost.\n",
      "\n",
      "Score:\n",
      ">> # Model Response Evaluation\n",
      "\n",
      "## Input\n",
      "Instruction: Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "## Expected Output\n",
      "Correct output: Jane Austen.\n",
      "\n",
      "## Model Response Score\n",
      "Score: 0 (completely incorrect)\n",
      "\n",
      "The model response \"The author of 'Pride and Prejudice' is Robert Frost.\" contains several errors:\n",
      "\n",
      "1. Robert Frost was an American poet, not the author of 'Pride and Prejudice'.\n",
      "2. The correct title of Jane Austen's novel is actually \"Pride and Prejudice\", not just \"Pride and Prejudice\".\n",
      "\n",
      "Therefore, the model response score is 0 out of 100.\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct output `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry[\"output\"])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", query_model(prompt))\n",
    "    print(\"\\n-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_scores(json_data, json_key, model=\"llama3.2\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model=model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  10%|█         | 11/110 [00:03<00:33,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: The correct output should be:\n",
      "\n",
      " Prime numbers: 11, 19\n",
      " Composite numbers: 14\n",
      "\n",
      "Score: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  15%|█▌        | 17/110 [00:05<00:30,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: 50\n",
      "\n",
      "The corrected response should be:\n",
      "\n",
      "Mercury - Liquid\n",
      "Oxygen - Gas\n",
      "Wood - Solid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  16%|█▋        | 18/110 [00:05<00:33,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: 80\n",
      "\n",
      "A note was left by someone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  29%|██▉       | 32/110 [00:09<00:25,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: The rewritten sentence is: \"It's very easy.\"\n",
      "\n",
      "Score: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  44%|████▎     | 48/110 [00:12<00:15,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: Statement. \n",
      "90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  46%|████▋     | 51/110 [00:14<00:30,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: 80\n",
      "\n",
      "The original text has an error in the verb form of \"birds\". The correct form should be \"sing\" instead of \"sings\". The corrected response is `The birds sing beautiful songs.`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  61%|██████    | 67/110 [00:18<00:15,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: The rewritten sentence as a question is: \"Did the dog chase the cat?\"\n",
      "\n",
      "Score: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  65%|██████▍   | 71/110 [00:19<00:11,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: Score: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  67%|██████▋   | 74/110 [00:22<00:35,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: 60\n",
      "\n",
      "Technical documents are instructional texts that provide detailed information about a product, process, or service, often including technical specifications and instructions for use or installation. They can be written in various styles, but their primary purpose is to inform or instruct the reader on how to accomplish something.\n",
      "\n",
      "In this case, the provided text fits the definition of a technical document because it explicitly mentions installing software and provides instructions for doing so. The text's focus on providing step-by-step guidance makes it an example of a technical document.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  79%|███████▉  | 87/110 [00:27<00:15,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: 80\n",
      "\n",
      "The sentence \"Me and my friend went to the store\" should be corrected to \"My friend and I went to the store.\" \n",
      "\n",
      "As for the additional response \"The store was very crowded\", it does not seem related to the original task of correcting a sentence, so I will ignore it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  98%|█████████▊| 108/110 [00:32<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: The classification of the sentence 'Please open the door.' is imperative.\n",
      "\n",
      "Score: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|██████████| 110/110 [00:33<00:00,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 99 of 110\n",
      "Average score: 43.26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to further improve the model\n",
    "- Tune hyperparamters: learning rate, batch size, no. epochs, etc.\n",
    "- Increase training dataset size\n",
    "- Diversify examples\n",
    "- Experiment w/ different prompts and instruction formats\n",
    "- Use a larger pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nex steps\n",
    "- Preference fine tuning: customize a model to better align w/ specific user preference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
